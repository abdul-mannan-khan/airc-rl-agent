{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE viewer notebook for JetBot\n",
    "===\n",
    "\n",
    "This notebook can visualize reconstructioned image by vae. This repository using JetBot camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from learning_racer.vae import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameter\n",
    "\n",
    "|Name | Description| Default|\n",
    "|:----|:-----------|:-------|\n",
    "|IMAGE_CHANNELS | Image channel such as RGB | 3 Not change|\n",
    "|VARIANTS_SIZE  | Variants size of VAE      | 32          |\n",
    "|MODEL_PATH     | Trained VAE model file path | ../../vae.torch|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CHANNELS = 3\n",
    "VARIANTS_SIZE = 32\n",
    "MODEL_PATH = '../../../vae.torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained VAE model.\n",
    "Loading trained VAE model on GPU memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "vae = VAE(image_channels=IMAGE_CHANNELS, z_dim=VARIANTS_SIZE)\n",
    "vae.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))\n",
    "vae.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create camera \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance(width=320, height=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocess and postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    observe = PIL.Image.fromarray(image)\n",
    "    observe = observe.resize((160,120))\n",
    "    croped = observe.crop((0, 40, 160, 120))\n",
    "    tensor = transforms.ToTensor()(croped)\n",
    "    return tensor\n",
    "    \n",
    "\n",
    "def rgb8_to_jpeg(image):\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize latent space function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_LATENT_MAX_VALUE = 3\n",
    "PANEL_HEIGHT = 10\n",
    "PANEL_WIDTH = 10\n",
    "\n",
    "def sigmoid(x, gain=1, offset_x=0):\n",
    "    return ((np.tanh(((x+offset_x)*gain)/2)+1)/2)\n",
    "\n",
    "def color_bar_rgb(x):\n",
    "    gain = 10\n",
    "    offset_x= 0.2\n",
    "    offset_green = 0.6\n",
    "    x = (x * 2) - 1\n",
    "    red = sigmoid(x, gain, -1*offset_x)\n",
    "    blue = 1-sigmoid(x, gain, offset_x)\n",
    "    green = sigmoid(x, gain, offset_green) + (1-sigmoid(x,gain,-1*offset_green))\n",
    "    green = green - 1.0\n",
    "    return [blue * 255,green * 255,red * 255]\n",
    "\n",
    "def _get_color(value):\n",
    "    t = (value + ABS_LATENT_MAX_VALUE) / (ABS_LATENT_MAX_VALUE * 2.0)\n",
    "    color = color_bar_rgb(t)\n",
    "    return color\n",
    "\n",
    "def create_color_panel(latent_spaces):\n",
    "    images = []\n",
    "    for z in latent_spaces:\n",
    "        p = np.zeros((PANEL_HEIGHT, PANEL_WIDTH, 3))\n",
    "        color = _get_color(z)\n",
    "        p += color[::-1]\n",
    "        p = np.clip(p, 0, 255)\n",
    "        images.append(p)\n",
    "    panel = np.concatenate(images, axis=1)\n",
    "    return panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = widgets.Image(format='jpeg', width=320, height=240)\n",
    "resize = widgets.Image(format='jpeg', width=160, height=80)\n",
    "result = widgets.Image(format='jpeg', width=160, height=80)\n",
    "camera_link = traitlets.dlink((camera,'value'), (image,'value'), transform=bgr8_to_jpeg)\n",
    "color_bar = widgets.Image(format='jpeg', width=32*PANEL_WIDTH, height=10*PANEL_HEIGHT)\n",
    "text = widgets.FloatText(value=0.0, description='BCE loss')\n",
    "display(image)\n",
    "display(widgets.HBox([resize,result]))\n",
    "display(color_bar)\n",
    "display(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'camera' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-830387e7001b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0;31m###\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mm_vae_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0mvae_process\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'new'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mcamera\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0mcamera\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobserve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvae_process\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'value'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'camera' is not defined"
     ]
    }
   ],
   "source": [
    "def vae_process(change):\n",
    "    image = change['new']\n",
    "    image = preprocess(image)\n",
    "    resize.value = rgb8_to_jpeg(np.transpose(np.uint8(image*255),[1,2,0]))\n",
    "    image = torch.unsqueeze(image, dim=0).to(device)\n",
    "    z, _ ,_ = vae.encode(image)\n",
    "    reconst,sigma = vae.decode(z)\n",
    "    to_visualize = torch.squeeze(reconst).detach().cpu().numpy()\n",
    "    #Why ? reconstruction image change RGB.\n",
    "    to_visualize = np.transpose(np.uint8(to_visualize*255),[1,2,0])[:,:,::-1]\n",
    "    result.value = rgb8_to_jpeg(to_visualize)\n",
    "    latent_space = z.detach().cpu().numpy()[0]\n",
    "    color_bar.value = rgb8_to_jpeg(create_color_panel(latent_space))\n",
    "    ###\n",
    "    m_vae_loss = (image - reconst)**2 / sigma\n",
    "    m_vae_loss = 0.5 * torch.sum(m_vae_loss)\n",
    "    #     bce_loss = F.binary_cross_entropy(reconst.view(-1, 38400),\n",
    "    #                                       image.view(-1, 38400),\n",
    "    #                                       reduction='sum')\n",
    "    #     mse_loss = F.mse_loss(reconst, image)\n",
    "    ###\n",
    "    text.value = m_vae_loss.item()\n",
    "vae_process({'new': camera.value})\n",
    "camera.observe(vae_process, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(vae_process, names='value')\n",
    "camera.stop()\n",
    "camera_link.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}